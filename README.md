# DETR-ResNet-101: Un Enfoque para la SegmentaciÃ³n PanÃ³ptica
Este proyecto es una implementaciÃ³n simplificada del modelo DETR (DEtection TRansformer) propuesto por Facebook AI Research, aplicado especÃ­ficamente a la tarea de segmentaciÃ³n panÃ³ptica.  
Utiliza Streamlit para la visualizaciÃ³n interactiva de los resultados y permite probar el modelo de manera local en un entorno aislado.

La aplicaciÃ³n permite cargar una imagen y obtener como salida una segmentaciÃ³n panÃ³ptica que combina detecciÃ³n de instancias y segmentaciÃ³n semÃ¡ntica, todo en una sola arquitectura basada en transformers.

## ğŸ§  Arquitectura de SegmentaciÃ³n PanÃ³ptica con DETR

<p align="center">
  <img src="static/DETR_101.png" alt="Ejemplo de segmentaciÃ³n 1" width="500"/>
</p>

La arquitectura utilizada en este proyecto extiende el modelo **DETR (DEtection TRansformer)** para realizar **segmentaciÃ³n panÃ³ptica**, combinando detecciÃ³n de objetos y segmentaciÃ³n semÃ¡ntica en una sola estructura unificada. A continuaciÃ³n, se describen brevemente sus componentes principales:

- **Imagen de entrada**: Se ingresa una imagen RGB de dimensiones `[3 Ã— H Ã— W]`.
- **Embeddings de cajas**: Se generan embeddings aprendibles que representan posibles regiones de interÃ©s (objetos o Ã¡reas).
- **Transformers y atenciÃ³n mÃºltiple (Multi-head Attention)**: Estos embeddings interactÃºan con la imagen codificada mediante atenciÃ³n, generando mapas que destacan diferentes regiones de la imagen.
- **Backbone FPN-CNN**: Se utilizan caracterÃ­sticas extraÃ­das de varias capas de ResNet (Res2 a Res5), combinadas mediante una red tipo FPN para refinar la segmentaciÃ³n.
- **MÃ¡scaras de salida (logits)**: Se generan mÃ¡scaras binarias para cada regiÃ³n detectada, de tamaÃ±o `[N Ã— H/4 Ã— W/4]`.
- **PredicciÃ³n final (Pixel-wise Argmax)**: Cada pÃ­xel es clasificado con una etiqueta Ãºnica, resultando en una segmentaciÃ³n panÃ³ptica completa donde se identifican tanto "cosas" (como vacas) como "stuff" (como cielo o pasto).

Esta arquitectura permite una segmentaciÃ³n precisa y semÃ¡nticamente rica sin necesidad de postprocesamiento adicional como NMS.

## ğŸ” Â¿QuÃ© hace este modelo?
**DETR-ResNet-101 Panoptic** es un modelo basado en *Transformers* que permite:

- Realizar **segmentaciÃ³n panÃ³ptica** precisa combinando detecciÃ³n de objetos y segmentaciÃ³n semÃ¡ntica.
- Identificar tanto **cosas** (objetos individuales) como **stuff** (regiones amorfas).
- Generar salidas con **mÃ¡scaras, clases e instancias Ãºnicas** por pÃ­xel.
- Usar una arquitectura **end-to-end** sin necesidad de postprocesamiento como NMS.

## ğŸ“¸ Ejemplos de SegmentaciÃ³n PanÃ³ptica

A continuaciÃ³n, se muestran algunos ejemplos del resultado generado por la aplicaciÃ³n. Cada imagen representa una salida panÃ³ptica del modelo **DETR-ResNet-101**, combinando detecciÃ³n de instancias y segmentaciÃ³n semÃ¡ntica.

<p align="center">
  <img src="static/panoptic_example1.png" alt="Ejemplo de segmentaciÃ³n 1" width="500"/>
</p>

<p align="center">
  <img src="static/panoptic_example2.png" alt="Ejemplo de segmentaciÃ³n 2" width="500"/>
</p>

Cada regiÃ³n de la imagen estÃ¡ coloreada segÃºn la clase identificada, y el modelo asigna un ID Ãºnico por instancia cuando corresponde.

## ğŸ› ï¸ TecnologÃ­as Utilizadas

<p align="center">
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python" />
  <img src="https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white" alt="Streamlit" />
  <img src="https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white" alt="Docker" />
  <img src="https://img.shields.io/badge/Transformers-HuggingFace-yellow?style=for-the-badge&logo=huggingface&logoColor=black" alt="Transformers" />
  <img src="https://img.shields.io/badge/Detectron2-Facebook-1877F2?style=for-the-badge&logo=facebook&logoColor=white" alt="Detectron2" />
</p>

## ğŸš€ Despliegue del Proyecto

Sigue estos pasos para ejecutar la aplicaciÃ³n localmente:

### Prerrequisitos
- Git instalado en tu sistema
- Docker instalado y funcionando

1. **Clonar el repositorio**
   ```bash
   git clone https://github.com/sslo12/DETR-Inference-101
   cd DETR-Inference-101
   ```

2. **Construir la imagen Docker**
   ```bash
   docker build -t detr-panoptic .
   ```

3. **Ejecutar el contenedor**
   ```bash
   docker run -p 8501:8501 detr-panoptic
   ```

4. **Acceder a la aplicaciÃ³n**
   
   Abre tu navegador web y visita:
   ```
   http://localhost:8501/
   ```

### Notas Adicionales
- El puerto `8501` es el puerto por defecto de Streamlit
- AsegÃºrate de que el puerto 8501 estÃ© disponible en tu sistema

## ğŸ“ Estructura del proyecto
```
DETR-Inference-101/
â”‚
â”œâ”€â”€ pages/                             # Scripts para las diferentes secciones de la aplicaciÃ³n
â”‚   â”œâ”€â”€ about_detr.py                  # PÃ¡gina con informaciÃ³n sobre el modelo DETR
â”‚   â”œâ”€â”€ inference_imgs.py              # LÃ³gica para inferencia en imÃ¡genes cargadas
â”‚   â”œâ”€â”€ panoptic_inference_camera.py   # Inferencia panÃ³ptica utilizando la cÃ¡mara
â”‚   â””â”€â”€ panoptic_segmentation.py       # informaciÃ³n sobre la segmentaciÃ³n panÃ³ptica
â”‚
â”œâ”€â”€ static/                            # Carpeta para archivos estÃ¡ticos
â”‚
â”œâ”€â”€ .gitignore                         # Archivos y carpetas ignoradas por Git
â”œâ”€â”€ Dockerfile                         # ConfiguraciÃ³n para contenedor Docker
â”œâ”€â”€ README.md                          # DocumentaciÃ³n principal del proyecto 
â”œâ”€â”€ home.py                            # Script de pÃ¡gina principal de la aplicaciÃ³n
â””â”€â”€ requirements.txt                   # Lista de dependencias del proyecto Python 
```
## ğŸ‘¥ CrÃ©ditos de Desarrollo

Esta implementaciÃ³n fue realizada como una prueba acadÃ©mica de inferencia y visualizaciÃ³n del modelo **DETR-ResNet-101** aplicado a la **segmentaciÃ³n panÃ³ptica**.  
No somos autores del modelo original, Ãºnicamente replicamos su funcionamiento como parte de una actividad de aprendizaje.

**Desarrollado por:**

- MarÃ­a JosÃ© Clavijo Rojas  
- Shirley Stefany Lombana
- Santiago Valencia
---

## Referencias

Este proyecto estÃ¡ basado en el modelo DETR publicado por Facebook AI Research.

- **Paper:**
  Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov, A., & Zagoruyko, S. (2020). *End-to-End Object Detection with Transformers*. arXiv preprint arXiv:2005.12872. https://doi.org/10.48550/arXiv.2005.12872

- **Repositorio oficial de GitHub:**  
  [https://github.com/facebookresearch/detr](https://github.com/facebookresearch/detr)
